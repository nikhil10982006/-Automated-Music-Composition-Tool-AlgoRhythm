# -*- coding: utf-8 -*-
"""AI Music Generator

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GR_Q7IC8dd3nTctI3tVFW_eBjcUqhVX5
"""

!pip install music21 pretty_midi
from google.colab import files
uploaded = files.upload()

import music21
import glob
import pickle

notes = []

# Parse all uploaded .mid files
for file in uploaded.keys():
    midi = music21.converter.parse(file)
    print(f"Parsing {file}")

    notes_to_parse = None

    try:  # File has instrument parts
        parts = music21.instrument.partitionByInstrument(midi)
        notes_to_parse = parts.parts[0].recurse()
    except:  # File has flat notes
        notes_to_parse = midi.flat.notes

    for element in notes_to_parse:
        if isinstance(element, music21.note.Note):
            notes.append(str(element.pitch))
        elif isinstance(element, music21.chord.Chord):
            notes.append('.'.join(str(n) for n in element.normalOrder))

# Save notes
with open('notes.pkl', 'wb') as f:
    pickle.dump(notes, f)

print("Total notes extracted:", len(notes))

import numpy as np

sequence_length = 100

with open('notes.pkl', 'rb') as f:
    notes = pickle.load(f)

pitchnames = sorted(set(notes))
n_vocab = len(pitchnames)

note_to_int = dict((note, number) for number, note in enumerate(pitchnames))

network_input = []
network_output = []

for i in range(len(notes) - sequence_length):
    seq_in = notes[i:i + sequence_length]
    seq_out = notes[i + sequence_length]
    network_input.append([note_to_int[n] for n in seq_in])
    network_output.append(note_to_int[seq_out])

n_patterns = len(network_input)

X = np.reshape(network_input, (n_patterns, sequence_length, 1))
X = X / float(n_vocab)

y = np.eye(n_vocab)[network_output]

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dropout, Dense, Activation

model = Sequential()
model.add(LSTM(512, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))
model.add(Dropout(0.3))
model.add(LSTM(512))
model.add(Dense(256))
model.add(Dropout(0.3))
model.add(Dense(n_vocab))
model.add(Activation('softmax'))

model.compile(loss='categorical_crossentropy', optimizer='adam')
model.fit(X, y, epochs=20, batch_size=64)

import random

start = np.random.randint(0, len(network_input) - 1)
pattern = network_input[start]

int_to_note = dict((number, note) for number, note in enumerate(pitchnames))

generated_notes = []

for note_index in range(500):
    input_seq = np.reshape(pattern, (1, len(pattern), 1))
    input_seq = input_seq / float(n_vocab)

    prediction = model.predict(input_seq, verbose=0)
    index = np.argmax(prediction)
    result = int_to_note[index]

    generated_notes.append(result)
    pattern.append(index)
    pattern = pattern[1:]

from music21 import stream, note, chord

output_notes = []

for n in generated_notes:
    if '.' in n or n.isdigit():
        notes_in_chord = n.split('.')
        chord_notes = [note.Note(int(n)) for n in notes_in_chord]
        new_chord = chord.Chord(chord_notes)
        new_chord.offset = len(output_notes)
        output_notes.append(new_chord)
    else:
        new_note = note.Note(n)
        new_note.offset = len(output_notes)
        output_notes.append(new_note)

midi_stream = stream.Stream(output_notes)
midi_stream.write('midi', fp='generated_music.mid')

files.download('generated_music.mid')